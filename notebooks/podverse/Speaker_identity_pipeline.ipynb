{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c802781",
   "metadata": {},
   "source": [
    "# Speaker identity pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b76202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.rendered_html.text_cell_render {max-width:600px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML, Markdown, Image, Video\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, Button, Output \n",
    "display(HTML(\"<style>.rendered_html.text_cell_render {max-width:600px; }</style>\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgnai.audio.embeddings import get_embedding\n",
    "from cgnai.utils import cgnai_home\n",
    "from cgnai.fileio import ls, load\n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from cgnai.audio.diarization import (get_superpixel_sim_matrix, \n",
    "                                     optimize_labels, \n",
    "                                     make_speaker_map, \n",
    "                                     get_speaker_timeline)\n",
    "import torch\n",
    "\n",
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 lex_#330.mp3\n"
     ]
    }
   ],
   "source": [
    "# Path to `mp3`-files\n",
    "# data_path = cgnai_home()/\"shared/podverse/data/dlf_politik_podcast/\"\n",
    "data_path = cgnai_home()/\"local/data/Lex_Fridman_Podcast/Examples\"\n",
    "files = list(data_path.rglob(\"*.mp3\"))\n",
    "files = [f.name for f in files]\n",
    "print(len(files), files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdce367",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir =  data_path\n",
    "!mkdir -p $results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45766bd1",
   "metadata": {},
   "source": [
    "## Helper\n",
    "\n",
    "**Note** They might be specific to the \"DLF Politik\" podcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(data_path/\"episode_info.json\", \"r\") as f:\n",
    "    episode_info = json.load(f)\n",
    "\n",
    "    \n",
    "files_to_episode_ids = {}\n",
    "for episode_id, info in episode_info.items():\n",
    "    url   = info['audio_url']\n",
    "    fname = Path(urlparse(url).path).name\n",
    "    \n",
    "    assert fname in files\n",
    "        \n",
    "    files_to_episode_ids[fname] = int(episode_id)\n",
    "    \n",
    "def get_episode_id(fname):\n",
    "    return files_to_episode_ids[fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848ca12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2394e34a",
   "metadata": {},
   "source": [
    "## Step 1: Generate embeddings\n",
    "\n",
    "Load mp3's and compute vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb8930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex_#330.mp3\n",
      "lex_#329.mp3\n",
      "lex_#328.mp3\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file)\n",
    "    wav, sr = torchaudio.load(data_path/file, format=\"mp3\")\n",
    "    emb     = get_embedding(wav, sr, device=dev)\n",
    "    np.save(str(data_path / file) + \"_emb.npy\", emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c79515",
   "metadata": {},
   "source": [
    "## Step 2: Generate Super Pixels and similarity matrices\n",
    "\n",
    "Take vector embeddings and compute similarity matrices and super pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8fa46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex_#330.mp3\n",
      "INFO superpixels|  min_pixels: 337\n",
      "T:  10120\n",
      "N0: 3373\n",
      "N:  2117\n",
      "lex_#329.mp3\n",
      "INFO superpixels|  min_pixels: 367\n",
      "T:  11010\n",
      "N0: 3670\n",
      "N:  2429\n",
      "lex_#328.mp3\n",
      "INFO superpixels|  min_pixels: 577\n",
      "T:  17316\n",
      "N0: 5772\n",
      "N:  3680\n"
     ]
    }
   ],
   "source": [
    "from cgnai.audio.superpixels import find_super_pixels, plot_super_pixels\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    \n",
    "    emb = load(str(data_path / file) + \"_emb.npy\")\n",
    "    emb = emb/(np.linalg.norm(emb, axis=1,keepdims=True))\n",
    "    d   = emb@emb.T\n",
    "    \n",
    "    # Number of segments at start\n",
    "    N0 = round(20 * d.shape[0]/60) \n",
    "    \n",
    "    # Run super pixel heuristic\n",
    "    # and save data\n",
    "    I = find_super_pixels(d, N0 = N0, mu = 0.0001, min_pixels_per_min = 2)\n",
    "    np.save(str(results_dir/file) + \"_super_pixels.npy\", np.array(I))\n",
    "    \n",
    "    \n",
    "    print(f\"T:  {d.shape[0]}\")\n",
    "    print(f\"N0: {N0}\")\n",
    "    print(f\"N:  {len(I)-1}\")\n",
    "    # ------------------------------\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.title(f\"{file}\")\n",
    "    plt.imshow(d, interpolation=\"none\")\n",
    "    plt.savefig(str(results_dir / file) + \"_sim.jpg\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = plot_super_pixels(I,d)\n",
    "    plt.savefig(str(results_dir / file) + \"_super_pixels.jpg\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ba60c",
   "metadata": {},
   "source": [
    "<img src=\"_temp/der_politik_podcast_folge_148_corona_geld_und_die_dlf_20200515_0117_44862193.mp3_super_pixels.jpg\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819cba08",
   "metadata": {},
   "source": [
    "## Step 3: Generate Diarization\n",
    "\n",
    "Compute optimized speaker ids from super pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b157cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "# Colormaps for visualizations below\n",
    "viridis   = cm.get_cmap('tab10', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white     = np.array([1,1,1, 1])\n",
    "newcolors[:1, :] = white\n",
    "speaker_cm = ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9271bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lex_#330.mp3\n",
      "1 lex_#329.mp3\n",
      "2 lex_#328.mp3\n"
     ]
    }
   ],
   "source": [
    "from cgnai.audio.diarization import (get_superpixel_sim_matrix, \n",
    "                                     optimize_labels, \n",
    "                                     make_speaker_map, \n",
    "                                     get_speaker_timeline)\n",
    "from os.path import exists\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    print(i, file)\n",
    "    \n",
    "    # Load embeddings\n",
    "    # and similarity matrix\n",
    "    emb = load(str(data_path / file) + \"_emb.npy\")\n",
    "    emb = emb/(np.linalg.norm(emb, axis=1,keepdims=True))\n",
    "    d   = emb@emb.T\n",
    "    \n",
    "    # load super pixels\n",
    "    # and create speaker map\n",
    "    I = load(str(data_path / file) + \"_super_pixels.npy\")\n",
    "    M = get_superpixel_sim_matrix(d, I)\n",
    "    ids, logp = optimize_labels(M, I, max_speaker=10)\n",
    "    sm = make_speaker_map(I, ids)\n",
    "    \n",
    "    # Save speaker ids\n",
    "    np.save(str(data_path / file) + \"_speaker_ids.npy\", ids)\n",
    "    # -------------------------------\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.imshow(sm, interpolation=\"None\", cmap=speaker_cm, vmin=0, vmax=np.max(ids))\n",
    "    plt.savefig(str(data_path / file) + \"_speaker_map.jpg\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.hist(get_speaker_timeline(ids,I), bins=len(set(ids)));\n",
    "    plt.savefig(str(data_path / file) + \"_times.jpg\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0facfc66",
   "metadata": {},
   "source": [
    "## Step 4: Extract Authors\n",
    "\n",
    "For each episode we want to define a superset of speakers. That is,  the list should contain at least names of all present speakers, but can contain more.\n",
    "\n",
    "**Note.** This part of the pipeline is specific to the \"DLF Politik\" podcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(data_path/\"episode_info.json\", \"r\") as f:\n",
    "    episode_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b253b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_author(author):\n",
    "    if ',' in author:\n",
    "        i = author.find(',')\n",
    "        author = author[i+1:].strip() + ' ' + author[0:i].strip()\n",
    "    return author.strip()\n",
    "\n",
    "def parse_from_authors_field(info):\n",
    "    if '|' not in info['author']:\n",
    "        return None\n",
    "    authors = info['author'][0:info['author'].find('|')]\n",
    "    authors = authors.split(';')\n",
    "    return list(map(normalize_author, authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f342c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load(\"flair/ner-german\")\n",
    "\n",
    "def parse_authors_from_details(info):\n",
    "    txt = info['details'] + ' ' + info['description']\n",
    "    sentence = Sentence(txt)\n",
    "    tagger.predict(sentence)\n",
    "    authors = [entity.text for entity in sentence.get_spans('ner') if entity.tag=='PER']\n",
    "    return list(set(map(normalize_author, authors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_authors(info):\n",
    "    authors = parse_from_authors_field(info)\n",
    "    if authors is not None:\n",
    "        return authors\n",
    "    authors = parse_authors_from_details(info)\n",
    "    return list(filter(lambda a: ' ' in a, authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e445da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "all_authors          = set()\n",
    "files_to_authors     = defaultdict(list)\n",
    "files_to_episode_ids = {}\n",
    "\n",
    "for episode_id, info in episode_info.items():\n",
    "    url   = info['audio_url']\n",
    "    fname = Path(urlparse(url).path).name\n",
    "    \n",
    "    assert fname in files\n",
    "    \n",
    "    a = parse_authors(info)\n",
    "    \n",
    "    files_to_authors[fname] = a\n",
    "    files_to_episode_ids[fname] = int(episode_id)\n",
    "    \n",
    "    all_authors.update(a)\n",
    "    \n",
    "def get_episode_id(fname):\n",
    "    return files_to_episode_ids[fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(data_path / \"episode_authors.json\", \"w\") as f:\n",
    "    json.dump(files_to_authors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81eeeb",
   "metadata": {},
   "source": [
    "## Step 5: Set up and solve factor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(data_path / \"episode_authors_clean.json\", \"r\") as f:\n",
    "    files_to_authors = json.load(f)\n",
    "\n",
    "all_authors=set()\n",
    "authors_to_files=defaultdict(set)\n",
    "for fname, authors in files_to_authors.items():\n",
    "    for author in authors:\n",
    "        authors_to_files[author].add(fname)\n",
    "    all_authors.update(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15c1bc",
   "metadata": {},
   "source": [
    "### Load super pixels, IDs, embeddings into mem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgnai.audio.similarities import load_ids, load_super_pixels, load_embedding\n",
    "\n",
    "ids = {}\n",
    "Is = {}\n",
    "embs = {}\n",
    "for i, fname in enumerate(files):\n",
    "    ids[fname] = load_ids(data_path / fname)\n",
    "    Is[fname] = load_super_pixels(data_path / fname)\n",
    "    embs[fname] = load_embedding(data_path / fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94ae1f",
   "metadata": {},
   "source": [
    "### Solve factor graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a22e82-dbb2-49da-b5a3-fb7f79f9da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeline(episode_id):\n",
    "    fname = [f for f in files if \"folge_103\" in f][0]\n",
    "    plt.plot(get_speaker_timeline(ids[fname], Is[fname])[80:86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import factorgraph as fg\n",
    "from cgnai.audio.similarities import get_clusters, get_cluster_similarity\n",
    "\n",
    "\n",
    "\n",
    "def create_factor_graph(fnames, ids, Is, embs, rv_constraints, constrained_files):\n",
    "    g = fg.Graph()\n",
    "    \n",
    "    print(f\"processing {len(fnames)} episodes\")\n",
    "    constrained_authors_count = 0\n",
    "    for fname in fnames:\n",
    "        emb = embs[fname]\n",
    "        authors = files_to_authors[fname]\n",
    "        cls, timeline = get_clusters(ids[fname], Is[fname])\n",
    "        for cl in cls.keys():\n",
    "            rv_id = f\"{get_episode_id(fname)}_{cl}\"\n",
    "            g.rv(rv_id, len(authors), labels=authors, meta={'fname': fname, 'cl': cl})\n",
    "            if rv_id in rv_constraints:\n",
    "                F = np.zeros((len(authors)))\n",
    "                F[authors.index(rv_constraints[rv_id])] = 1.0\n",
    "                g.factor([rv_id], potential=F)\n",
    "                constrained_authors_count += 1\n",
    "                \n",
    "        \n",
    "        S = get_cluster_similarity(cls, emb, cls, emb)\n",
    "        for i, cl1 in enumerate(cls.keys()):\n",
    "            for j, cl2 in enumerate(cls.keys()):\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                s = min(S[i, j]/0.6, 1.0)\n",
    "                F = np.ones((len(authors), len(authors))) * (1 - s)\n",
    "                np.fill_diagonal(F, s)\n",
    "                g.factor(\n",
    "                    [f\"{get_episode_id(fname)}_{cl1}\",\n",
    "                     f\"{get_episode_id(fname)}_{cl2}\"],\n",
    "                    potential = F\n",
    "                )\n",
    "    print(f\"added {constrained_authors_count} name constraints\")\n",
    "    for a, fname_a in enumerate(fnames):\n",
    "        \n",
    "        emb_a = embs[fname_a]\n",
    "        authors_a = np.array(files_to_authors[fname_a])\n",
    "        cls_a, _ = get_clusters(ids[fname_a], Is[fname_a])\n",
    "        \n",
    "        for b, fname_b in enumerate(fnames):\n",
    "            if a >= b:\n",
    "                continue\n",
    "            emb_b = embs[fname_b]\n",
    "            authors_b = np.array(files_to_authors[fname_b])\n",
    "            cls_b, _ = get_clusters(ids[fname_b], Is[fname_b])\n",
    "            \n",
    "            S = get_cluster_similarity(cls_a, emb_a, cls_b, emb_b)\n",
    "            for i, cl_i in enumerate(cls_a.keys()):\n",
    "                for j, cl_j in enumerate(cls_b.keys()):\n",
    "                    s = min(S[i, j]/0.6, 1.0)\n",
    "                    F = np.where(authors_a[:, None]==authors_b[None, :], s, 1-s)\n",
    "                    g.factor(\n",
    "                        [f\"{get_episode_id(fname_a)}_{cl_i}\",\n",
    "                         f\"{get_episode_id(fname_b)}_{cl_j}\"],\n",
    "                        potential = F\n",
    "                    )\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_given_size(a, size):\n",
    "    splits = np.split(a, np.arange(size,len(a),size))\n",
    "    if len(splits[-1]) < size / 2 and len(splits) > 1:\n",
    "        splits[-2] = np.concatenate((splits[-2], splits[-1]))\n",
    "        return splits[:-1]\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44555772-7a71-4ae0-9f09-788689f75d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# maps RV names to authors.\n",
    "rv_constraints={} # rv_name => author\n",
    "\n",
    "constrained_authors_to_files = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for author, fnames in sorted(authors_to_files.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    # Set up factor graph, including rv constraints\n",
    "    print(\">\",author, len(fnames))\n",
    "    \n",
    "    n_episodes = 5\n",
    "    for fnames_ in split_given_size(np.array(list(fnames)), n_episodes):\n",
    "        g = create_factor_graph(fnames_, ids, Is, embs, rv_constraints, constrained_authors_to_files[author])\n",
    "        iters, converged = g.lbp(normalize=True,  max_iters=100)\n",
    "        if not converged:\n",
    "            print(f\"NOT CONVERGED!\")\n",
    "            continue\n",
    "        marginals = g.rv_marginals(normalize=True)\n",
    "        for rv, probs in marginals:\n",
    "            for n in range(0,probs.shape[0]):\n",
    "                authors = files_to_authors[rv.meta['fname']]\n",
    "                fname = rv.meta['fname']\n",
    "                cl = rv.meta['cl']\n",
    "                if probs[n] > 0.99: # authors[n] == author and \n",
    "                    rv_id = f\"{get_episode_id(fname)}_{cl}\"\n",
    "                    if rv_id in rv_constraints and authors[n] != rv_constraints[rv_id]:\n",
    "                        print(f\"{rv_constraints[rv_id]} -> {authors[n]}\")\n",
    "                    rv_constraints[rv_id] = authors[n]\n",
    "                    constrained_authors_to_files[authors[n]].add(fname)\n",
    "        print(f\"# of identified speakers: {len(rv_constraints)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0969a-3700-491f-a02f-d2b417bebc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0,20):\n",
    "    fnames_ = random.sample(files, 10)\n",
    "    fnames_ = [f for f in fnames_ if f in files_to_authors and len(files_to_authors[f]) > 1]\n",
    "    \n",
    "    g = create_factor_graph(fnames_, ids, Is, embs, rv_constraints, constrained_authors_to_files[author])\n",
    "    iters, converged = g.lbp(normalize=True,  max_iters=100)\n",
    "    if not converged:\n",
    "        print(f\"NOT CONVERGED!\")\n",
    "        continue\n",
    "    marginals = g.rv_marginals(normalize=True)\n",
    "    for rv, probs in marginals:\n",
    "        for n in range(0,probs.shape[0]):\n",
    "            authors = files_to_authors[rv.meta['fname']]\n",
    "            fname = rv.meta['fname']\n",
    "            cl = rv.meta['cl']\n",
    "            if probs[n] > 0.99: # authors[n] == author and \n",
    "                rv_id = f\"{get_episode_id(fname)}_{cl}\"\n",
    "                if rv_id in rv_constraints and authors[n] != rv_constraints[rv_id]:\n",
    "                    print(f\"{rv_constraints[rv_id]} -> {authors[n]}\")\n",
    "                rv_constraints[rv_id] = authors[n]\n",
    "                constrained_authors_to_files[authors[n]].add(fname)\n",
    "    print(f\"# of identified speakers: {len(rv_constraints)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f373056",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79976824-12d6-4718-b6e9-e095cfed6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_timestamp(timestamp):\n",
    "    try:\n",
    "        t=datetime.strptime(timestamp, '%H:%M:%S.%f')\n",
    "    except:\n",
    "        t=datetime.strptime(timestamp, '%M:%S.%f')\n",
    "    s = round(t.microsecond/1000000)\n",
    "    return timedelta(hours=t.hour, minutes=t.minute, seconds=(t.second+s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e49f2-3a77-49c9-b6b1-9440345bc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[files.index(f) for f in constrained_authors_to_files['Ann-Kathrin Büüsker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7525865-4dae-4fab-ae1c-b144ff3c4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fname(eid):\n",
    "    return [f for f in files if (\"folge_\" + str(eid)) in f][0]\n",
    "\n",
    "def get_fname_index(eid):\n",
    "    return files.index(get_fname(eid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180b15c-40e3-4bbe-b451-532df6568471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_speaker_annotate_transcript(transcript, timeline, ids_to_names):\n",
    "    for line in transcript:\n",
    "        (t0, t1), txt = line\n",
    "        t0 = round(t0.total_seconds())\n",
    "        t0 = max(t0 - 2, 0)\n",
    "        t1 = round(t1.total_seconds())\n",
    "        t1 = min(t1 - 2, len(timeline))\n",
    "        ids = timeline[t0:t1]\n",
    "        speaker_id = Counter(ids).most_common(1)[0][0]\n",
    "        \n",
    "        if speaker_id in ids_to_names:\n",
    "            name = f'{ids_to_names[speaker_id]:>20}'\n",
    "        else:\n",
    "            name = f'                    '\n",
    "        ids = f'{str(ids):>20}'\n",
    "        print(f'{t0:>5}', name,ids, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73770d07-2704-4277-b316-b43374aa70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcript(mp3_path):\n",
    "    transcript = []\n",
    "    with open(str(mp3_path) + \".vtt\", \"r\") as f:\n",
    "        ls = f.readlines()[2:]\n",
    "        timestamps = ls[0::3]\n",
    "        txt = ls[1::3]\n",
    "        for entry in zip(timestamps, txt):\n",
    "            t0, t1 = entry[0].split(\"-->\")\n",
    "            \n",
    "            t0 = parse_timestamp(t0.strip())\n",
    "            t1 = parse_timestamp(t1.strip())\n",
    "            txt = entry[1].strip()\n",
    "            transcript.append(((t0, t1),txt))\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda08650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_episode(f):\n",
    "    if isinstance(f, int):\n",
    "        fname = files[f]\n",
    "    else:\n",
    "        fname = f\n",
    "    episode_id = get_episode_id(fname)\n",
    "    mp3_path = data_path / fname\n",
    "    transcript = load_transcript(mp3_path)\n",
    "    I = load_super_pixels(mp3_path)\n",
    "    ids = load_ids(mp3_path)\n",
    "    timeline = get_speaker_timeline(ids, I)\n",
    "    ids_to_names = {}\n",
    "    for i in set(ids):\n",
    "        if f\"{episode_id}_{i}\" in rv_constraints:\n",
    "            ids_to_names[i] = rv_constraints[f\"{episode_id}_{i}\"]\n",
    "    print(files_to_authors[fname])\n",
    "    plt.hist([ids_to_names[i] for i in ids if i in ids_to_names]);\n",
    "    plt.show()\n",
    "    print(f'============ {fname} ============')\n",
    "    print_speaker_annotate_transcript(transcript, timeline, ids_to_names)\n",
    "show_episode(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transcript_document(transcript, timeline, ids_to_names):\n",
    "    doc = []\n",
    "    for line in transcript:\n",
    "        (t0, t1), txt = line\n",
    "        t0 = round(t0.total_seconds())\n",
    "        t0 = max(t0 - 2, 0)\n",
    "        t1 = round(t1.total_seconds())\n",
    "        t1 = min(t1 - 2, len(timeline))\n",
    "        ids = timeline[t0:t1]\n",
    "        if len(ids) == 0:\n",
    "            continue\n",
    "        speaker_id = Counter(ids).most_common(1)[0][0]\n",
    "        if speaker_id in ids_to_names:\n",
    "            doc.append({\n",
    "                \"start\": t0,\n",
    "                \"end\": t1,\n",
    "                \"speaker\": ids_to_names[speaker_id],\n",
    "                \"text\": txt\n",
    "            })\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7fc2a-aefa-4a18-a84f-464cf2808b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transcript_document_for_file_index(i):\n",
    "    fname = files[i]\n",
    "    episode_id = get_episode_id(fname)\n",
    "    mp3_path = data_path / fname\n",
    "    transcript = load_transcript(mp3_path)\n",
    "    I = load_super_pixels(mp3_path)\n",
    "    ids = load_ids(mp3_path)\n",
    "    timeline = get_speaker_timeline(ids, I)\n",
    "    ids_to_names = {}\n",
    "    for i in set(ids):\n",
    "        if f\"{episode_id}_{i}\" in rv_constraints:\n",
    "            ids_to_names[i] = rv_constraints[f\"{episode_id}_{i}\"]\n",
    "    lines = create_transcript_document(transcript, timeline, ids_to_names)\n",
    "    return {\n",
    "        \"filename\": fname,\n",
    "        \"episode_id\": episode_id,\n",
    "        \"transcript\": lines\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "speaker_texts = defaultdict(list)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    doc = create_transcript_document_for_file_index(i)['transcript']\n",
    "    speakers = [x['speaker'] for x in doc]\n",
    "    for k, g in groupby(enumerate(speakers), lambda x: x[1]):\n",
    "        text = []\n",
    "        start = None\n",
    "        for g_ in map(itemgetter(0), g):\n",
    "            text.append(doc[g_]['text'])\n",
    "            if start is None:\n",
    "                start = doc[g_]['start']\n",
    "        text = ' '.join(text)\n",
    "        speaker_texts[k].append((text, file, start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7612cf3-35bd-4371-a682-d06309aa3f6c",
   "metadata": {},
   "source": [
    "# Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adac953-e98b-4c86-b7ef-886d28d832e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/06/83jjb3_j5px4gbhqmmjqhv240000gn/T/ipykernel_73461/1927031230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c09946d-98c9-4da5-bf5d-7c1e1073ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(\n",
    "    \"http://localhost:9200\"\n",
    ")\n",
    "\n",
    "# Successful response!\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1638c",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe059031",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(index=\"transcripts\", body={\n",
    "\"mappings\": {\n",
    "    \"properties\": {\n",
    "        \"transcript\":{\n",
    "            \"type\":\"nested\"\n",
    "        },\n",
    "        \"episode_id\": { \"type\": \"integer\" },\n",
    "        \"filename\": { \"type\": \"keyword\"  },\n",
    "        \n",
    "    }\n",
    "}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe62842",
   "metadata": {},
   "source": [
    "## Insert Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b8891-f96f-495f-98f8-743b77cbb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(files)):\n",
    "    doc = create_transcript_document_for_file_index(i)\n",
    "    resp = client.index(index=\"transcripts\", id=i, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a66e19",
   "metadata": {},
   "source": [
    "## Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def query_transcripts(author, query):\n",
    "    q = {\n",
    "        \"nested\": {\n",
    "            \"path\": \"transcript\",\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\"match\": {\"transcript.speaker\": author}},\n",
    "                        {\"match\": {\"transcript.text\": query}}\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"inner_hits\" : {}\n",
    "        }\n",
    "    }\n",
    "    resp=client.search(index=\"transcripts\", query=q, source=False, docvalue_fields=[\"episode_id\", \"filename\"])\n",
    "    return [{\n",
    "        'episode_id': r['fields']['episode_id'][0],\n",
    "        'filename': r['fields']['filename'][0],\n",
    "        'hits': [\n",
    "            {\n",
    "                'speaker': i['_source']['speaker'],\n",
    "                'start': i['_source']['start'],\n",
    "                'end': i['_source']['end'],\n",
    "                'text': i['_source']['text']\n",
    "            } for i in r['inner_hits']['transcript']['hits']['hits']\n",
    "        ]\n",
    "    } for r in resp['hits']['hits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_transcripts(\"Frank Capellan\", \"Krieg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_episode(get_fname(272))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca4f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
