{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3193614",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, Button, Output \n",
    "display(HTML(\"<style>.rendered_html.text_cell_render {max-width:600px; }</style>\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed537d7",
   "metadata": {},
   "source": [
    "# Precompute embeddings\n",
    "\n",
    "Resourses and useful links:\n",
    "\n",
    " - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c18ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "\n",
    "#ximp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "plot = plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a01c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "#ximp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#ximp\n",
    "import torch\n",
    "import numpy as np\n",
    "from cgnai.utils import cgnai_home, sliding_window_ind\n",
    "from cgnai.fileio import load, dump, ls\n",
    "from cgnai.audio.mels import cut_up\n",
    "import torchaudio\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from cgnai.audio.utils import compute_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99876d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "import numpy as np\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio import Inference\n",
    "\n",
    "seg_pipe = Pipeline.from_pretrained(\"pyannote/speaker-segmentation\")\n",
    "\n",
    "def compute_segs(w,sr):\n",
    "    res  = seg_pipe({\"waveform\": w[[0]], \"sample_rate\": sr})\n",
    "    segs = res.get_timeline().segments_list_\n",
    "    return np.array([(round(s.start * sr), round(s.end*sr)) for s in segs])\n",
    "\n",
    "va_pipe = Pipeline.from_pretrained(\"pyannote/voice-activity-detection\")\n",
    "\n",
    "def compute_va(w, sr):\n",
    "    \"\"\"Voice Activity.\"\"\"\n",
    "    res = va_pipe({\"waveform\": w[[0]], \"sample_rate\": sr})\n",
    "    return np.array([(round(x.start*sr), round(x.end*sr)) for x in res._tracks.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52806d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot(Z):\n",
    "#     plt.figure(figsize=(4,1))\n",
    "#     for i,z in enumerate(Z):\n",
    "#         if isinstance(z, slice): z = [z.start, z.stop]  \n",
    "#         plt.plot([z[0]/sr,z[1]/sr],[i,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52499509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accum(Z, d):\n",
    "#     v = np.zeros(len(S))\n",
    "\n",
    "#     for z in Z:\n",
    "#         if isinstance(z, slice): z = [z.start, z.stop]\n",
    "#         r0 = (z[0] - 25600)//d + 1\n",
    "#         r1 = z[1]//d  \n",
    "#         i0 = max(r0,0)\n",
    "#         i1 = min(r1,len(v)-1)\n",
    "\n",
    "#         v[i0:i1] += 1\n",
    "        \n",
    "#     return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125a3ee",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "#xargs\n",
    "xdir  = Path(\"./\")\n",
    "xtask = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b080cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "path = cgnai_home()/\"shared/podverse/data/politik_podcast\"\n",
    "is_mp3 = lambda s: s.endswith(\".mp3\")\n",
    "\n",
    "fnames = list(filter(is_mp3, ls(path).files))\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54501245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "\n",
    "#xarg\n",
    "t = 1; range(19)\n",
    "\n",
    "fname = fnames[t]\n",
    "torchaudio.set_audio_backend(\"sox_io\") # Can't load mp3 otherwise on my Macbook\n",
    "wav, sr =  torchaudio.load(str(path/fname))\n",
    "\n",
    "\n",
    "print(fname)\n",
    "print(wav.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "#xarg\n",
    "dur  = 1.6; [0.8, 1.6, 2.4, 3.2, 4.0] # cut width for the embeddings \n",
    "\n",
    "step = min(dur, 1.0)\n",
    "\n",
    "emb = Inference(\"pyannote/embedding\", window=\"sliding\", duration=dur, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "x = emb({\"waveform\":wav[[0]], \"sample_rate\": sr})\n",
    "x = x.data\n",
    "\n",
    "dump(x, str(xdir/\"emb.pkl\")) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "x = x/np.linalg.norm(x, axis=1, keepdims=True)\n",
    "d = x@x.T\n",
    "\n",
    "dump(d, xdir/\"sim.pkl\") ####\n",
    "\n",
    "fig, axs = plt.subplot_mosaic([[0],[1]], \n",
    "                          sharey=False,\n",
    "                          gridspec_kw = dict(width_ratios=[1], height_ratios=[4,1]),\n",
    "                          figsize=(4, 6), layout=\"constrained\")\n",
    "axs[0].imshow(d);\n",
    "axs[1].hist(d.flatten(), bins=np.linspace(0,1,50));\n",
    "\n",
    "plt.savefig(xdir/\"summary.jpg\", bbox_inches='tight', dpi=100) ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bffb2e",
   "metadata": {},
   "source": [
    "# NBX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30146bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgnai.nbx import create_bundle\n",
    "create_bundle(\"_nbx_embeddings_fixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e756e0",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e03b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
