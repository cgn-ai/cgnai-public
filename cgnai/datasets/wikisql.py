# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb.

# %% auto 0
__all__ = ['get_val', 'query_args', 'query', 'prepare_question', 'prepare_table', 'prepare_sql', 'WikiSQLDataset']

# %% ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb 8
import json
import numpy as np
import pandas as pd
import pandasql as ps
import sys

from pprint import pprint
from pathlib import Path

from ..fileio import *
from ..utils import listmap, cgnai_home

# %% ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb 9
def get_val(key):
    return lambda x: x[key]

# %% ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb 11
from ..thirdparty.wikisql import Query, Table

def query_args(d):
    return {'sel_index' : d["sql"]["sel"],
            'agg_index' : d["sql"]["agg"],
            'conditions': d["sql"]["conds"]}

def query(d, t):
    """
    Returns an executable SQL statement.
    
    I adapted the `__repr__` method of the `Query` class so `pandasql` doesn't complain.
    """
    q = Query(**query_args(d))
    
    if q.agg_index == 0:
        rep = 'SELECT {sel} FROM mytable'.format(
            sel='col{}'.format(q.sel_index))
    else:
        rep = 'SELECT {agg} ({sel}) FROM mytable'.format(
            agg=q.agg_ops[q.agg_index],
            sel='col{}'.format(q.sel_index))
    
    
    escape = lambda s: s.replace("'", "''")
    wrap_str = lambda v: v if type(v) != str else f"'{escape(v)}'"
    
    if q.conditions:
        rep +=  ' WHERE ' + ' AND '.join(['{} {} {}'.format('col{}'.format(i), q.cond_ops[o], wrap_str(v)) for i, o, v in q.conditions])
    return rep

# %% ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb 12
def prepare_question(d):
    s = "<Q>"
    s += d["question"]
    return s

# %% ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb 13
def prepare_table(t):
    tag = "<T>"
    sep   = "<SEP>"
    s = ""
    s += sep.join(t['header'])
    return f"{tag}mytable<SEP>{s}"

# %% ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb 14
def prepare_sql(d, t):
    return query(d, t)

# %% ../notebooks/nlq/datasets/01_WikiSQL_dataset.ipynb 18
from torch.utils.data import Dataset
from pathlib import Path

class WikiSQLDataset(Dataset):
    def __init__(self, path="./_data/WikiSQL/", partition="train", fix_case=False):
        path = Path(path)
        self.path = path
        self.partition = partition

        datapath = path/"data"
    
        # load datapoints
        D = load(datapath/f"{partition}.jsonl", format=".txt")
        D = D[:-1]                 # removes last line wich is an empty string
        D = listmap(json.loads, D) # data contains json strings
        self.D = D
        
        # load tabledata
        T = load(datapath/f"{partition}.tables.jsonl", format=".txt")
        T = T[:-1]
        T = listmap(json.loads, T)
        ids = listmap(get_val("id"), T) # get a list of the table ids
        self.T = T
        self.T_ids = ids
        if fix_case:
            for d in self.D:
                conditions = d["sql"]["conds"]
                t = self.T[self.T_ids.index(d["table_id"])]
                if conditions:
                    # Fix the casing of constant arguments in the ground-truth SQL statement.
                    df = pd.DataFrame(t["rows"], columns = t["header"])
                    for c in conditions:
                        try:
                            vs = df.iloc[:, c[0]].unique()
                            idx = [v.lower() for v in vs if isinstance(v, str)].index(c[2])
                            c[2] = vs[idx]
                        except ValueError:
                            pass
                
        
    def __len__(self): return len(self.D)
    def __getitem__(self, i):
        d = self.D[i]
        t = self.T[self.T_ids.index(d["table_id"])]
        
        x = prepare_question(d) + prepare_table(t)
        y = prepare_sql(d, t)
        
        return i,x,y
    def query_table(self, i, query, rename=True):
        d = self.D[i]
        t = self.T[self.T_ids.index(d["table_id"])]
        df = pd.DataFrame(t["rows"], columns = t["header"])
    
        if rename is True:
            header_dict = dict(zip(t["header"], [f"col{j}" for j in range(len(t["header"]))]))
            df.rename(columns=header_dict, inplace=True)

        return ps.sqldf(query, {"mytable" : df})
